import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import vstack
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# Load dataset (replace with your actual dataset path)
df = pd.read_csv("your_dataset.csv")  # Update with your actual file

# Assuming the dataset has 'text' and 'label' columns
X = df['text'].astype(str)
y = df['label']

# Split data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize vectorizer with optimized parameters
vectorizer = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.8, stop_words='english', dtype=np.float32)

# Fit and transform training data
X_train_tfidf = vectorizer.fit_transform(X_train)

# Process test data in chunks to avoid MemoryError
batch_size = 10000  # Adjust based on memory
num_batches = int(np.ceil(len(X_test) / batch_size))
vectorized_chunks = []

for i in range(num_batches):
    chunk = X_test[i * batch_size: (i + 1) * batch_size]
    vectorized_chunk = vectorizer.transform(chunk)  # Use transform instead of fit_transform
    vectorized_chunks.append(vectorized_chunk)

# Combine all chunks
X_test_tfidf = vstack(vectorized_chunks)

# Train model
model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

# Predict on test data
y_pred = model.predict(X_test_tfidf)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')
